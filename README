Fpart - README

What is fpart ?
***************

Fpart is a tool that helps you sort file trees and pack them into bags (called
"partitions"). It is developped in C and available under the BSD license.

It splits a list of directories and file trees into a certain number of
partitions, trying to produce partitions with the same size and number of files.
It can also produce partitions with a given number of files or a limited size.

Once generated, partitions are either printed as file lists to stdout (default)
or to files. Those lists can then be used by third party programs.

Fpart also includes a live mode, which allows it to crawl very large filesystems
and produce partitions in live. Hooks are available to act on those partitions
(e.g. immediatly start a transfer using rsync(1)) without having to wait for
the filesystem traversal job to be finished. Used this way, fpart can be seen
as a powerful data migration tool.

Compatibility :
***************

Fpart has been successfully tested on :

* FreeBSD (7x, 8x, 9x, amd64)
* GNU/Linux (x86_64, arm)
* Solaris 10 (i386)
* Solaris 9 (Sparc)
* NetBSD (amd64, alpha)

and will probably work on other operating systems too.

Examples - common usage :
*************************

The following will produce 3 partitions, with (approximatively) the same size
and number of files. This can be used (for example) to launch several rsync
commands in parallel. 3 files, "var-parts.[0-2]", are generated as output :

$ fpart -n 3 -o var-parts /var

The following will produce partitions of 4.3 GB, containing music files ready
to be burnt to a DVD (for example). Files "music-parts.[0-n]", are generated
as output :

$ fpart -s 4617089843 -o music-parts /path/to/my/music

The following will produce partitions containing 10000 files each by examining
/usr first and then /home and display only partition 0 on stdout :

$ find /usr ! -type d | ./fpart -f 10000 -i - /home | grep '^0:'

The following will produce two partitions by re-using du(1) output. Fpart will
not examine the filesystem but instead re-use arbitrary values printed by du(1)
and sort them :

$ du * | fpart -n 2 -a

Examples - migrating data :
***************************

The following example will show you how to use fpart, GNU Parallel and Rsync to
split up a directory and immediately schedule data synchronization of smaller
lists of files, while FS crawling goes on. We will be synchronizing data from
/data/src to /data/dest.

First, go to the source directory (as rsync's --files-from option takes a file
list relative to its source directory) :

$ cd /data/src

Then, run fpart from here :

$ fpart -L -f 10000 -x '.snapshot' -x '.zfs' -Z -o /tmp/part.out -W \
  'SHELL=/bin/sh HOME=/home/martymac
    /usr/local/bin/sem -j 3
      "/usr/local/bin/rsync -av --files-from=${FPART_PARTFILENAME}
        /data/src/ /data/dest/"' .

This command will start fpart in live mode (option -L), making it generate
partitions during FS crawling. Fpart will produce partitions containing at most
10000 files each (option -f), will skip files and folders named '.snapshot' or
'.zfs' (option -x) and will list empty and non-accessible directories (option
-Z; that option is necessary when working with rsync to make sure the whole file
tree will be re-created within the destination directory). Last but not least,
each partition will be written to /tmp/part.out.<n> (option -o; <n> is the
partition index and will be automatically added by fpart) and used within the
post-part hook (option -W), run immediately by fpart once the partition is
complete :

SHELL=/bin/sh HOME=/home/martymac /usr/local/bin/sem -j 3
    "/usr/local/bin/rsync -av --files-from=${FPART_PARTFILENAME} /data/src/ /data/dest/"

This hook is itself a nested command.  It will run GNU Parallel's sem scheduler
(any other scheduler will do) to run at most 3 rsync in parallel.

The scheduler will finally trigger the following command :

/usr/local/bin/rsync -av --files-from=${FPART_PARTFILENAME} /data/src/ /data/dest/

where ${FPART_PARTFILENAME} is not expanded yet and will be part of rsync's
environment when it runs (it is set by fpart). It will contain the file name of
the partition that has just been generated (other useful variables are
available, see fpart(1)).

That's all, folks ! Pretty simple, isn't it ?

In this basic example, file crawling and data transfer are run from the same
-local- machine, but you can use it as the basis of a much sophisticated 
solution : at work, by using a cluster of machines connected to our filers
through NFS and running Open Grid Scheduler, we successully migrated over
400 TB of data.

Installing :
************

To install fpart, get the 'Makefile' symlink point to the right Makefile,
e.g. :

# rm Makefile
# ln -s Makefile.linux Makefile

then, type in :

# make
# make install

See also :
**********

See fpart(1) for more details.

The partition problem is detailed here :
http://en.wikipedia.org/wiki/Partition_problem

and here :
http://en.wikipedia.org/wiki/Bin_packing_problem

I am sure you will also be interested in :
https://github.com/jbd/packo

which was developped by Jean-Baptiste Denis as the original proof of concept.

Author / Licence :
******************

Fpart has been written by Ganaël LAPLANCHE <ganael.laplanche@martymac.org>
and is available under the BSD license (see COPYING for details).

Thanks to Jean-Baptiste Denis for having given me the idea of this program !

Contributions :
***************

FTS code comes from FreeBSD :
    lib/libc/gen/fts.c -> fts.c
    include/fts.h -> fts.h
and is available under the BSD license.
